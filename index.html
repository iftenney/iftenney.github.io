<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ian  Tenney</title>
<meta name="description" content="Ian Tenney's personal website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  
  <a href="https://twitter.com/iftenney" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  <a href="https://scholar.google.com/citations?user=7WntHrAAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  
  <a href="https://github.com/iftenney" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  <a href="https://www.linkedin.com/in/iftenney" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
  
  
  
  
  
  <a href="https://research.google/people/IanTenney" target="_blank" title="Google Research"><i class="fab fa-google"></i></a>
</span>

        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
      
  <span class="first-name">Ian</span>  <span class="last-name">Tenney</span>


    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-left">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/iftenney.jpg">
      
      
    </div>
    

    <div class="clearfix main-text-content">
      <p>I am a software engineer on the <a href="https://ai.google/research/teams/language/">Language team</a> at Google Research. My research focuses on interpretability and analysis of deep NLP models (a.k.a. “<a href="https://twitter.com/tallinzen/status/1139514475147649026">BERTology</a>”). I’m interested in how these models encode linguistic structure, how these structures develop, and what they can tell us about model behavior and robustness. I’m also interested in the practical workflow of interpretability: how does the way we interact with these models inform our own mental models of how they work?</p>

<p>I’m one of the tech leads for the <a href="https://pair-code.github.io/lit/">Language Interpretability Tool <span class="nobreak">(<img src="/assets/img/fire_emoji.png" />LIT)</span></a>.</p>

<p>I am based in Seattle, but collaborate with researchers across many sites, including Google’s <a href="https://pair.withgoogle.com/">People + AI Research</a> and the <a href="https://lunar.cs.brown.edu/">LUNAR group</a> at Brown.</p>

<p>In 2018, I was a Senior Researcher on the <a href="https://jsalt18-sentence-repl.github.io/">Sentence Representation Learning Team</a> as part of the <a href="https://www.clsp.jhu.edu/workshops/18-workshop/">2018 JSALT workshop</a> at Johns Hopkins University. Among other things, I took this <a href="https://jsalt18-sentence-repl.github.io/group.jpg">terrible group photo</a>.</p>

<p>From 2016 to 2018, I taught <a href="https://www.ischool.berkeley.edu/courses/datasci/266">Data Science W266: Natural Language Processing with Deep Learning</a> at UC Berkeley School of Information.</p>

<p>In a past life, I was a physicist, studying ultrafast molecular and optical physics in the lab of <a href="https://web.stanford.edu/dept/app-physics/cgi-bin/person/bucksbaum-philip-h/">Philip H. Bucksbaum</a> at <a href="https://ultrafast.stanford.edu/">Stanford / SLAC</a>.</p>

<p>Contact: <code class="language-plaintext highlighter-rouge">"if" + lastname + "@gmail.com"</code></p>

    </div>

    

    <div class="projects">
      <h2>projects</h2>
      <div class="projects">
  <!-- <div class='row'> -->
  <div class="card-deck">

  
  
    <div class="card hoverable">
      
      <a href="https://pair-code.github.io/lit/" target="_blank">
      
      
      <img src="/assets/img/lit-660.gif" alt="project thumbnail" class="card-img-top">
      
      <div class="card-body">
        <h2 class="card-title">The Language Interpretability Tool <span class='nobreak'>(<img src="/assets/img/fire_emoji.png">LIT)</span></h2>
        <p class="card-text">An open-source platform for visualization and understanding of NLP models.</p>
        <div class="row ml-1 mr-1 p-0">
          
        </div>
      </div>
      </a>
    </div>
  
    <div class="card hoverable">
      
      <a href="/projects/bertology/">
      
      
      <img src="/assets/img/bertology-16x9.png" alt="project thumbnail" class="card-img-top">
      
      <div class="card-body">
        <h2 class="card-title">Probing and BERTology</h2>
        <p class="card-text">Understanding linguistic structure in pre-trained language models, such as ELMo and BERT.</p>
        <div class="row ml-1 mr-1 p-0">
          
        </div>
      </div>
      </a>
    </div>
  

  </div>
  <!-- </div> -->
</div>

    </div>

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/2020.emnlp-demos.15" target="_blank">EMNLP</a></abbr>
    
  
  </div>

  <div id="tenney2020lit" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2008.05122.pdf" target="_blank"><div class="title">The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  James Wexler,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jasmijn Bastings,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tolga Bolukbasi,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Andy Coenen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Sebastian Gehrmann,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellen Jiang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Mahima Pushkarna,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Carey Radebaugh,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Emily Reif,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ann Yuan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2008.05122" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.15" class="btn btn-sm z-depth-0" role="button" target="_blank">EMNLP 2020</a>
      
    
    
    
    
    
      <a href="https://ai.googleblog.com/2020/11/the-language-interpretability-tool-lit.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/PAIR-code/lit" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      <a href="https://pair-code.github.io/lit/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the Language Interpretability Tool (LIT), an open-source platform for visualization and understanding of NLP models. We focus on core questions about model behavior: Why did my model make this prediction? When does it perform poorly? What happens under a controlled change in the input? LIT integrates local explanations, aggregate analysis, and counterfactual generation into a streamlined, browser-based interface to enable rapid exploration and error analysis. We include case studies for a diverse set of workflows, including exploring counterfactuals for sentiment analysis, measuring gender bias in coreference systems, and exploring local behavior in text generation. LIT supports a wide range of models—including classification, seq2seq, and structured prediction—and is highly extensible through a declarative, framework-agnostic API. LIT is under active development, with code and full documentation available at https://github.com/pair-code/lit.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/P19-1452/" target="_blank">ACL</a></abbr>
    
  
  </div>

  <div id="tenney2019bert" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1905.05950.pdf" target="_blank"><div class="title">BERT Rediscovers the Classical NLP Pipeline</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 57th Conference of the Association for Computational Linguistics, </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1905.05950" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/P19-1452/" class="btn btn-sm z-depth-0" role="button" target="_blank">ACL 2019</a>
      
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant/tree/master/probing" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="/assets/pdf/bert-layer-poster-acl-final.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://openreview.net/forum?id=SJzSgnRcKX" target="_blank">ICLR</a></abbr>
    
  
  </div>

  <div id="tenney2019what" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1905.06316.pdf" target="_blank"><div class="title">What do you learn from context? Probing for sentence structure in contextualized word representations</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Patrick Xia,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Berlin Chen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alex Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Adam Poliak,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  R Thomas McCoy,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Najoung Kim,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Benjamin Van Durme,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Sam Bowman,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Learning Representations, </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1905.06316" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://openreview.net/forum?id=SJzSgnRcKX" class="btn btn-sm z-depth-0" role="button" target="_blank">ICLR 2019</a>
      
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant/tree/master/probing" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="/assets/pdf/edgeprobe-poster-iclr-final.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Ian  Tenney.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: January 11, 2021.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
