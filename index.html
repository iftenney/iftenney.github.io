<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ian  Tenney</title>
<meta name="description" content="Ian Tenney's personal website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RPS0P4NJ1V"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-RPS0P4NJ1V');
  </script>


    

  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  
  <a href="https://twitter.com/iftenney" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  <a href="http://sigmoid.social/@iftenney" rel="me" target="_blank" title="@iftenney@sigmoid.social"><i class="fab fa-mastodon"></i></a>
  
  
  <a href="https://scholar.google.com/citations?user=7WntHrAAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  
  <a href="https://github.com/iftenney" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  <a href="https://www.linkedin.com/in/iftenney" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
  
  
  
  
  
  <a href="https://research.google/people/IanTenney" target="_blank" title="Google Research"><i class="fab fa-google"></i></a>
</span>

        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
      
  <span class="first-name">Ian</span>  <span class="last-name">Tenney</span>


    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-left">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/iftenney.jpg">
      
      
    </div>
    

    <div class="clearfix main-text-content">
      <p>I am a Staff Research Scientist on the <a href="https://pair.withgoogle.com/">People + AI Research</a> (PAIR) team in Google Research. My work focuses on interpretability and model understanding for NLP, including attribution methods, counterfactual analysis, and visualizations, as well as “intrinsic” analysis (a.k.a. <a href="https://twitter.com/tallinzen/status/1139514475147649026">BERTology</a>) of linguistic phenomena in model representations.</p>

<p>I am a co-creator and TL of the <a href="https://pair-code.github.io/lit/">Learning Interpretability Tool <span class="nobreak">(<img src="/assets/img/fire_emoji.png" />LIT)</span></a>.</p>

<p>Previously, I’ve taught <a href="https://www.ischool.berkeley.edu/courses/datasci/266">an NLP course</a> at UC Berkeley School of Information. In a past life I was a physicist, studying ultrafast molecular and optical physics in the lab of <a href="https://profiles.stanford.edu/philip-bucksbaum">Philip H. Bucksbaum</a> at <a href="https://ultrafast.stanford.edu/">Stanford / SLAC</a>.</p>

<p>Contact: <code class="language-plaintext highlighter-rouge">"if" + lastname + "@gmail.com"</code> (or <code class="language-plaintext highlighter-rouge">@google.com</code>)</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Mar&nbsp;14,&nbsp;2023</th>
          <td>
            
              New preprint! <a href="https://arxiv.org/abs/2303.08114">Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs</a>. Check out this <a href="https://twitter.com/kelvin_guu/status/1637835146874478592">thread</a> for more.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec&nbsp;6,&nbsp;2022</th>
          <td>
            
              <a href="https://github.com/PAIR-code/lit/releases/tag/v0.5/"><img class="inline-image" src="/assets/img/fire_emoji.png" />LIT v0.5 released</a>, with new features for salience, aggregate analysis, and more - see <a href="https://twitter.com/iftenney/status/1600264155449425920">this thread</a> for an overview.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct&nbsp;6,&nbsp;2022</th>
          <td>
            
              <a href="https://arxiv.org/abs/2205.11482">Towards Tracing Factual Knowledge in Language Models Back to the Training Data</a> led by our excellent intern <a href="https://www.ekinakyurek.me/">Ekin Akyürek</a> accepted at Findings of EMNLP 2022.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    <div class="projects">
      <h2>projects</h2>
      <div class="projects">
  <!-- <div class='row'> -->
  <div class="card-deck">

  
  
    <div class="card hoverable">
      
      <a class="card-contents" href="https://pair-code.github.io/lit/" target="_blank">
      
      
      <div class="image-container">
        <img src="/assets/img/lit-660.gif" alt="project thumbnail" class="card-img-top">
      </div>
      
      <div class="card-body">
        <h2 class="card-title">The Learning Interpretability Tool (<img src="/assets/img/fire_emoji.png">LIT)</h2>
        <p class="card-text">An open-source platform for visualization and understanding of NLP models.</p>
        <div class="row ml-1 mr-1 p-0">
          
        </div>
      </div>
      </a>
    </div>
  
    <div class="card hoverable">
      
      <a class="card-contents" href="/projects/tda/">
      
      
      <div class="image-container">
        <img src="/assets/img/fact-tracing-figure1.png" alt="project thumbnail" class="card-img-top">
      </div>
      
      <div class="card-body">
        <h2 class="card-title">Training-Data Attribution</h2>
        <p class="card-text">Understanding model behavior by finding training examples that influence a particular prediction.</p>
        <div class="row ml-1 mr-1 p-0">
          
        </div>
      </div>
      </a>
    </div>
  
    <div class="card hoverable">
      
      <a class="card-contents" href="/projects/bertology/">
      
      
      <div class="image-container">
        <img src="/assets/img/bertology.png" alt="project thumbnail" class="card-img-top">
      </div>
      
      <div class="card-body">
        <h2 class="card-title">Probing and BERTology</h2>
        <p class="card-text">Understanding linguistic structure in pre-trained language models, such as ELMo and BERT.</p>
        <div class="row ml-1 mr-1 p-0">
          
        </div>
      </div>
      </a>
    </div>
  

  </div>
  <!-- </div> -->
</div>

    </div>

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://arxiv.org/abs/2303.08114" target="_blank">arXiv</a></abbr>
    
  
  </div>

  <div id="guu2023simfluence" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2303.08114.pdf" target="_blank"><div class="title">Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Kelvin Guu,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Albert Webson,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellie Pavlick,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Lucas Dixon,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Tolga Bolukbasi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint, </em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2303.08114" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
      <a href="https://twitter.com/kelvin_guu/status/1637835146874478592" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fab fa-twitter"></i>Thread</a>
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Training data attribution (TDA) methods offer to trace a model’s prediction on any given example back to specific influential training examples. Existing approaches do so by assigning a scalar influence score to each training example, under a simplifying assumption that influence is additive. But in reality, we observe that training examples interact in highly non-additive ways due to factors such as inter-example redundancy, training order, and curriculum learning effects.
To study such interactions, we propose Simfluence, a new paradigm for TDA where the goal is not to produce a single influence score per example, but instead a training run simulator: the user asks, “If my model had trained on example z1, then z2, ..., then zn, how would it behave on ztest?”; the simulator should then output a simulated training run, which is a time series predicting the loss on ztest at every step of the simulated run. This enables users to answer counterfactual questions about what their model would have learned under different training curricula, and to directly see where in training that learning would occur.
We present a simulator, Simfluence-Linear, that captures non-additive interactions and is often able to predict the spiky trajectory of individual example losses with surprising fidelity. Furthermore, we show that existing TDA methods such as TracIn and influence functions can be viewed as special cases of Simfluence-Linear. This enables us to directly compare methods in terms of their simulation accuracy, subsuming several prior TDA approaches to evaluation. In experiments on large language model (LLM) fine-tuning, we show that our method predicts loss trajectories with much higher accuracy than existing TDA methods (doubling Spearman’s correlation and reducing mean-squared error by 75%) across several tasks, models, and training methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://openreview.net/forum?id=K0E_F0gFDgA" target="_blank">ICLR</a></abbr>
    
  
  </div>

  <div id="sellam2022multiberts" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2106.16163.pdf" target="_blank"><div class="title">The MultiBERTs: BERT Reproductions for Robustness Analysis</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Thibault Sellam,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Steve Yadlowsky,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jason Wei,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Naomi Saphra,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alexander D’Amour,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tal Linzen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jasmijn Bastings,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Iulia Turc,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jacob Eisenstein,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICLR (spotlight), </em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2106.16163" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://openreview.net/forum?id=K0E_F0gFDgA" class="btn btn-sm z-depth-0" role="button" target="_blank">ICLR 2022</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/google-research/language/tree/master/language/multiberts" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Experiments with pre-trained models such as BERT are often based on a single checkpoint. While the conclusions drawn apply to the artifact tested in the experiment (i.e., the particular instance of the model), it is not always clear whether they hold for the more general procedure which includes the architecture, training data, initialization scheme, and loss function. Recent work has shown that repeating the pre-training process can lead to substantially different performance, suggesting that an alternative strategy is needed to make principled statements about procedures. To enable researchers to draw more robust conclusions, we introduce MultiBERTs, a set of 25 BERT-Base checkpoints, trained with similar hyper-parameters as the original BERT model but differing in random weight initialization and shuffling of training data. We also define the Multi-Bootstrap, a non-parametric bootstrap method for statistical inference designed for settings where there are multiple pre-trained models and limited test data. To illustrate our approach, we present a case study of gender bias in coreference resolution, in which the Multi-Bootstrap lets us measure effects that may not be detected with a single checkpoint. The models and statistical library are available online, along with an additional set of 140 intermediate checkpoints captured during pre-training to facilitate research on learning dynamics.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/2020.emnlp-demos.15" target="_blank">EMNLP</a></abbr>
    
  
  </div>

  <div id="tenney2020lit" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2008.05122.pdf" target="_blank"><div class="title">The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  James Wexler,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jasmijn Bastings,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tolga Bolukbasi,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Andy Coenen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Sebastian Gehrmann,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellen Jiang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Mahima Pushkarna,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Carey Radebaugh,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Emily Reif,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ann Yuan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2008.05122" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.15" class="btn btn-sm z-depth-0" role="button" target="_blank">EMNLP 2020</a>
      
    
    
    
    
    
    
      <a href="https://ai.googleblog.com/2020/11/the-language-interpretability-tool-lit.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/PAIR-code/lit" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
      
      <a href="/assets/pdf/lit-poster-emnlp-2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
      <a href="https://pair-code.github.io/lit/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the Language Interpretability Tool (LIT), an open-source platform for visualization and understanding of NLP models. We focus on core questions about model behavior: Why did my model make this prediction? When does it perform poorly? What happens under a controlled change in the input? LIT integrates local explanations, aggregate analysis, and counterfactual generation into a streamlined, browser-based interface to enable rapid exploration and error analysis. We include case studies for a diverse set of workflows, including exploring counterfactuals for sentiment analysis, measuring gender bias in coreference systems, and exploring local behavior in text generation. LIT supports a wide range of models—including classification, seq2seq, and structured prediction—and is highly extensible through a declarative, framework-agnostic API. LIT is under active development, with code and full documentation available at https://github.com/pair-code/lit.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/P19-1452/" target="_blank">ACL</a></abbr>
    
  
  </div>

  <div id="tenney2019bert" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1905.05950.pdf" target="_blank"><div class="title">BERT Rediscovers the Classical NLP Pipeline</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 57th Conference of the Association for Computational Linguistics, </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1905.05950" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/P19-1452/" class="btn btn-sm z-depth-0" role="button" target="_blank">ACL 2019</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant-v1-legacy/tree/master/probing" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
      
      <a href="/assets/pdf/bert-layer-poster-acl-2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://openreview.net/forum?id=SJzSgnRcKX" target="_blank">ICLR</a></abbr>
    
  
  </div>

  <div id="tenney2019what" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1905.06316.pdf" target="_blank"><div class="title">What do you learn from context? Probing for sentence structure in contextualized word representations</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Patrick Xia,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Berlin Chen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alex Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Adam Poliak,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  R Thomas McCoy,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Najoung Kim,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Benjamin Van Durme,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Sam Bowman,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Learning Representations, </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1905.06316" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://openreview.net/forum?id=SJzSgnRcKX" class="btn btn-sm z-depth-0" role="button" target="_blank">ICLR 2019</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant-v1-legacy/tree/master/probing" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
      
      <a href="/assets/pdf/edgeprobe-poster-iclr-2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2023 Ian  Tenney.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: May 13, 2023.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  

  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
