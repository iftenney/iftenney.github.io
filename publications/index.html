<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ian  Tenney | publications</title>
<meta name="description" content="Ian Tenney's personal website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RPS0P4NJ1V"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-RPS0P4NJ1V');
  </script>


    

  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
        
  <span class="first-name">Ian</span>  <span class="last-name">Tenney</span>


      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://arxiv.org/abs/2402.10524" target="_blank">arXiv</a></abbr>
    
  
  </div>

  <div id="kahng2024llm" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2402.10524.pdf" target="_blank"><div class="title">LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Minsuk Kahng,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Mahima Pushkarna,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Michael Xieyang Liu,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  James Wexler,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Emily Reif,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Krystal Kallarackal,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Minsuk Chang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Michael Terry,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Lucas Dixon
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint, </em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2402.10524" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Automatic side-by-side evaluation has emerged as a promising approach to evaluating the quality of responses from large language models (LLMs). However, analyzing the results from this evaluation approach raises scalability and interpretability challenges. In this paper, we present LLM Comparator, a novel visual analytics tool for interactively analyzing results from automatic side-by-side evaluation. The tool supports interactive workflows for users to understand when and why a model performs better or worse than a baseline model, and how the responses from two models are qualitatively different. We iteratively designed and developed the tool by closely working with researchers and engineers at a large technology company. This paper details the user challenges we identified, the design and development of the tool, and an observational study with participants who regularly evaluate their models.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://arxiv.org/abs/2312.11805" target="_blank">arXiv</a></abbr>
    
  
  </div>

  <div id="geminiteam2023gemini" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2312.11805.pdf" target="_blank"><div class="title">Gemini: A Family of Highly Capable Multimodal Models</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
               Gemini Team, Google
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint, </em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2312.11805" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://blog.google/technology/ai/google-gemini-ai/https://blog.google/technology/ai/google-gemini-ai/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of Gemini models in cross-modal reasoning and language understanding will enable a wide variety of use cases and we discuss our approach toward deploying them responsibly to users.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://dl.acm.org/doi/abs/10.1145/3563657.3596046" target="_blank">DIS</a></abbr>
    
  
  </div>

  <div id="ashtari2023discovery" class="col-sm-8">
    
      
        <a href="https://dl.acm.org/doi/abs/10.1145/3563657.3596046" target="_blank"><div class="title">From Discovery to Adoption: Understanding the ML Practitioners’ Interpretability Journey</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Narges Ashtari,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ryan Mullins,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Crystal Qian,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  James Wexler,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Mahima Pushkarna
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2023 ACM Designing Interactive Systems Conference, </em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://dl.acm.org/doi/abs/10.1145/3563657.3596046" class="btn btn-sm z-depth-0" role="button" target="_blank">DIS 2023</a>
      
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Models are interpretable when machine learning (ML) practitioners can readily understand the reasoning behind their predictions. Ironically, little is known about the ML practitioners’ experience of discovering and adopting novel interpretability techniques in production settings. In a qualitative study with 18 practitioners at a large technology company working with text data, we found that despite varied tasks, practitioners experienced nearly identical challenges related to interpretability methods in model analysis workflows. These stem from problem formulation, the social nature of interpretability investigations, and non-standard practices in cross-functional organizational contexts. A follow-up examination of early-stage design probes with seven practitioners suggests that self-reported experts are “perpetual intermediates”, who can benefit from regular, responsive, and in-situ education about interpretability methods across workflows, regardless of prior experience with models, analysis tools, or interpretability techniques. From these findings, we emphasize the need for multi-stage support for learning of interpretability methods for real-world NLP applications.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://arxiv.org/abs/2303.08114" target="_blank">arXiv</a></abbr>
    
  
  </div>

  <div id="guu2023simfluence" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2303.08114.pdf" target="_blank"><div class="title">Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Kelvin Guu,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Albert Webson,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellie Pavlick,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Lucas Dixon,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Tolga Bolukbasi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint, </em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2303.08114" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
      <a href="https://twitter.com/kelvin_guu/status/1637835146874478592" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fab fa-twitter"></i>Thread</a>
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Training data attribution (TDA) methods offer to trace a model’s prediction on any given example back to specific influential training examples. Existing approaches do so by assigning a scalar influence score to each training example, under a simplifying assumption that influence is additive. But in reality, we observe that training examples interact in highly non-additive ways due to factors such as inter-example redundancy, training order, and curriculum learning effects.
To study such interactions, we propose Simfluence, a new paradigm for TDA where the goal is not to produce a single influence score per example, but instead a training run simulator: the user asks, “If my model had trained on example z1, then z2, ..., then zn, how would it behave on ztest?”; the simulator should then output a simulated training run, which is a time series predicting the loss on ztest at every step of the simulated run. This enables users to answer counterfactual questions about what their model would have learned under different training curricula, and to directly see where in training that learning would occur.
We present a simulator, Simfluence-Linear, that captures non-additive interactions and is often able to predict the spiky trajectory of individual example losses with surprising fidelity. Furthermore, we show that existing TDA methods such as TracIn and influence functions can be viewed as special cases of Simfluence-Linear. This enables us to directly compare methods in terms of their simulation accuracy, subsuming several prior TDA approaches to evaluation. In experiments on large language model (LLM) fine-tuning, we show that our method predicts loss trajectories with much higher accuracy than existing TDA methods (doubling Spearman’s correlation and reducing mean-squared error by 75%) across several tasks, models, and training methods.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Findings of EMNLP</abbr>
    
  
  </div>

  <div id="akyurek2022tracing" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2205.11482.pdf" target="_blank"><div class="title">Tracing Knowledge in Language Models Back to the Training Data</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Ekin Akyürek,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tolga Bolukbasi,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Frederick Liu,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Binbin Xiong,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jacob Andreas,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Kelvin Guu
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Findings of the Association for Computational Linguistics: EMNLP, </em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2205.11482" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
    
    
    
    
    
      <a href="https://twitter.com/akyurekekin/status/1529281791194185730" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fab fa-twitter"></i>Thread</a>
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Language models (LMs) have been shown to memorize a great deal of factual knowledge contained in their training data. But when an LM generates an assertion, it is often difficult to determine where it learned this information and whether it is true. In this paper, we propose the problem of fact tracing: identifying which training examples taught an LM to generate a particular factual assertion. Prior work on training data attribution (TDA) may offer effective tools for identifying such examples, known as "proponents". We present the first quantitative benchmark to evaluate this. We compare two popular families of TDA methods – gradient-based and embedding-based – and find that much headroom remains. For example, both methods have lower proponent-retrieval precision than an information retrieval baseline (BM25) that does not have access to the LM at all. We identify key challenges that may be necessary for further improvement such as overcoming the problem of gradient saturation, and also show how several nuanced implementation details of existing neural TDA methods can significantly improve overall fact tracing performance.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://aclanthology.org/2022.acl-long.117" target="_blank">ACL</a></abbr>
    
  
  </div>

  <div id="paranjape2022rgf" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2110.07596.pdf" target="_blank"><div class="title">Retrieval-guided Counterfactual Generation for QA</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Bhargavi Paranjape,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Matthew Lamm,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                and <em>Ian Tenney</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, </em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2110.07596" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://aclanthology.org/2022.acl-long.117" class="btn btn-sm z-depth-0" role="button" target="_blank">ACL 2022</a>
      
    
    
    
    
    
      <a href="https://twitter.com/bvp22294/status/1449076657281593345" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fab fa-twitter"></i>Thread</a>
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep NLP models have been shown to be brittle to input perturbations. Recent work has shown that data augmentation using counterfactuals — i.e. minimally perturbed inputs — can help ameliorate this weakness. We focus on the task of creating counterfactuals for question answering, which presents unique challenges related to world knowledge, semantic diversity, and answerability. To address these challenges, we develop a Retrieve-Generate-Filter(RGF) technique to create counterfactual evaluation and training data with minimal human supervision. Using an open-domain QA framework and question generation model trained on original task data, we create counterfactuals that are fluent, semantically diverse, and automatically labeled. Data augmentation with RGF counterfactuals improves performance on out-of-domain and challenging evaluation sets over and above existing methods, in both the reading comprehension and open-domain QA settings. Moreover, we find that RGF data leads to significant improvements in a model’s robustness to local perturbations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://openreview.net/forum?id=K0E_F0gFDgA" target="_blank">ICLR</a></abbr>
    
  
  </div>

  <div id="sellam2022multiberts" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2106.16163.pdf" target="_blank"><div class="title">The MultiBERTs: BERT Reproductions for Robustness Analysis</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Thibault Sellam,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Steve Yadlowsky,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jason Wei,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Naomi Saphra,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alexander D’Amour,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tal Linzen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jasmijn Bastings,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Iulia Turc,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jacob Eisenstein,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICLR (spotlight), </em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2106.16163" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://openreview.net/forum?id=K0E_F0gFDgA" class="btn btn-sm z-depth-0" role="button" target="_blank">ICLR 2022</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/google-research/language/tree/master/language/multiberts" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Experiments with pre-trained models such as BERT are often based on a single checkpoint. While the conclusions drawn apply to the artifact tested in the experiment (i.e., the particular instance of the model), it is not always clear whether they hold for the more general procedure which includes the architecture, training data, initialization scheme, and loss function. Recent work has shown that repeating the pre-training process can lead to substantially different performance, suggesting that an alternative strategy is needed to make principled statements about procedures. To enable researchers to draw more robust conclusions, we introduce MultiBERTs, a set of 25 BERT-Base checkpoints, trained with similar hyper-parameters as the original BERT model but differing in random weight initialization and shuffling of training data. We also define the Multi-Bootstrap, a non-parametric bootstrap method for statistical inference designed for settings where there are multiple pre-trained models and limited test data. To illustrate our approach, we present a case study of gender bias in coreference resolution, in which the Multi-Bootstrap lets us measure effects that may not be detected with a single checkpoint. The models and statistical library are available online, along with an additional set of 140 intermediate checkpoints captured during pre-training to facilitate research on learning dynamics.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://arxiv.org/abs/2010.06032" target="_blank">arXiv</a></abbr>
    
  
  </div>

  <div id="webster2020measuring" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2010.06032.pdf" target="_blank"><div class="title">Measuring and reducing gendered correlations in pre-trained models</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Kellie Webster,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Xuezhi Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alex Beutel,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Emily Pitler,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellie Pavlick,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jilin Chen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Slav Petrov
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint, </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2010.06032" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://ai.googleblog.com/2020/10/measuring-gendered-correlations-in-pre.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Pre-trained models have revolutionized natural language understanding. However, researchers have found they can encode artifacts undesired in many applications, such as professions correlating with one gender more than another. We explore such gendered correlations as a case study for how to address unintended correlations in pre-trained models. We define metrics and reveal that it is possible for models with similar accuracy to encode correlations at very different rates. We show how measured correlations can be reduced with general-purpose techniques, and highlight the trade offs different strategies have. With these results, we make recommendations for training robust models: (1) carefully evaluate unintended correlations, (2) be mindful of seemingly innocuous configuration differences, and (3) focus on general mitigations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/2020.emnlp-demos.15" target="_blank">EMNLP</a></abbr>
    
  
  </div>

  <div id="tenney2020lit" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2008.05122.pdf" target="_blank"><div class="title">The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  James Wexler,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jasmijn Bastings,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tolga Bolukbasi,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Andy Coenen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Sebastian Gehrmann,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellen Jiang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Mahima Pushkarna,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Carey Radebaugh,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Emily Reif,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ann Yuan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2008.05122" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.15" class="btn btn-sm z-depth-0" role="button" target="_blank">EMNLP 2020</a>
      
    
    
    
    
    
    
      <a href="https://ai.googleblog.com/2020/11/the-language-interpretability-tool-lit.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/PAIR-code/lit" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
      
      <a href="/assets/pdf/lit-poster-emnlp-2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
      <a href="https://pair-code.github.io/lit/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the Language Interpretability Tool (LIT), an open-source platform for visualization and understanding of NLP models. We focus on core questions about model behavior: Why did my model make this prediction? When does it perform poorly? What happens under a controlled change in the input? LIT integrates local explanations, aggregate analysis, and counterfactual generation into a streamlined, browser-based interface to enable rapid exploration and error analysis. We include case studies for a diverse set of workflows, including exploring counterfactuals for sentiment analysis, measuring gender bias in coreference systems, and exploring local behavior in text generation. LIT supports a wide range of models—including classification, seq2seq, and structured prediction—and is highly extensible through a declarative, framework-agnostic API. LIT is under active development, with code and full documentation available at https://github.com/pair-code/lit.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/2020.emnlp-main.552" target="_blank">EMNLP</a></abbr>
    
  
  </div>

  <div id="michael2020asking" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2004.14513.pdf" target="_blank"><div class="title">Asking without Telling: Exploring Latent Ontologies in Contextual Representations</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Julian Michael,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jan A. Botha,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                and <em>Ian Tenney</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2004.14513" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/2020.emnlp-main.552" class="btn btn-sm z-depth-0" role="button" target="_blank">EMNLP 2020</a>
      
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The success of pretrained contextual encoders, such as ELMo and BERT, has brought a great deal of interest in what these models learn: do they, without explicit supervision, learn to encode meaningful notions of linguistic structure? If so, how is this structure encoded? To investigate this, we introduce latent subclass learning (LSL): a modification to classifier-based probing that induces a latent categorization (or ontology) of the probe’s inputs. Without access to fine-grained gold labels, LSL extracts emergent structure from input representations in an interpretable and quantifiable form. In experiments, we find strong evidence of familiar categories, such as a notion of personhood in ELMo, as well as novel ontological distinctions, such as a preference for fine-grained semantic roles on core arguments. Our results provide unique new evidence of emergent structure in pretrained encoders, including departures from existing annotations which are inaccessible to earlier methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/2020.findings-emnlp.439" target="_blank">Findings of EMNLP</a></abbr>
    
  
  </div>

  <div id="zhang2020scales" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2010.05345.pdf" target="_blank"><div class="title">Do Language Embeddings capture Scales?</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Xikun Zhang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Deepak Ramachandran,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Yanai Elazar,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Dan Roth
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Findings of the Association for Computational Linguistics: EMNLP, </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2010.05345" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.439" class="btn btn-sm z-depth-0" role="button" target="_blank">Findings of EMNLP 2020</a>
      
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge. One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects. We show that pretrained language models capture a significant amount of this information but are short of the capability required for general common-sense reasoning. We identify contextual information in pre-training and numeracy as two key factors affecting their performance, and show that a simple method of canonicalizing numbers can have a significant effect on the results.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/2020.blackboxnlp-1.4" target="_blank">BlackboxNLP</a></abbr>
    
  
  </div>

  <div id="merchant2020happens" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2004.14448.pdf" target="_blank"><div class="title">What Happens To BERT Embeddings During Fine-tuning?</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Amil Merchant,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Elahe Rahimtoroghi,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellie Pavlick,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                and <em>Ian Tenney</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2004.14448" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/2020.blackboxnlp-1.4" class="btn btn-sm z-depth-0" role="button" target="_blank">BlackboxNLP 2020</a>
      
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While much recent work has examined how linguistic information is encoded in pre-trained sentence representations, comparatively little is understood about how these models change when adapted to solve downstream tasks. Using a suite of analysis techniques—supervised probing, unsupervised similarity analysis, and layer-based ablations—we investigate how fine-tuning affects the representations of the BERT model. We find that while fine-tuning necessarily makes some significant changes, there is no catastrophic forgetting of linguistic phenomena. We instead find that fine-tuning is a conservative process that primarily affects the top layers of BERT, albeit with noteworthy variation across tasks. In particular, dependency parsing reconfigures most of the model, whereas SQuAD and MNLI involve much shallower processing. Finally, we also find that fine-tuning has a weaker effect on representations of out-of-domain sentences, suggesting room for improvement in model generalization.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/2020.acl-demos.15" target="_blank">ACL</a></abbr>
    
  
  </div>

  <div id="pruksachatkun2020jiant" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/2003.02249.pdf" target="_blank"><div class="title">jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Yada Pruksachatkun,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Phil Yeres,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Haokun Liu,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jason Phang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Phu Mon Htut,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alex Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Samuel R. Bowman
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, </em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/2003.02249" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/2020.acl-demos.15" class="btn btn-sm z-depth-0" role="button" target="_blank">ACL 2020</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
    
    
      <a href="https://jiant.info/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We introduce jiant, an open source toolkit for conducting multitask and transfer learning experiments on English NLU tasks. jiant enables modular and configuration driven experimentation with state-of-the-art models and a broad set of tasks for probing, transfer learning, and multitask training experiments. jiant implements over 50 NLU tasks, including all GLUE and SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published performance on a variety of tasks and models, e.g., RoBERTa and BERT.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/P19-1452/" target="_blank">ACL</a></abbr>
    
  
  </div>

  <div id="tenney2019bert" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1905.05950.pdf" target="_blank"><div class="title">BERT Rediscovers the Classical NLP Pipeline</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 57th Conference of the Association for Computational Linguistics, </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1905.05950" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/P19-1452/" class="btn btn-sm z-depth-0" role="button" target="_blank">ACL 2019</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant-v1-legacy/tree/master/probing" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
      
      <a href="/assets/pdf/bert-layer-poster-acl-2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/P19-1439/" target="_blank">ACL</a></abbr>
    
  
  </div>

  <div id="wang2019can" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1812.10860.pdf" target="_blank"><div class="title">Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Alex Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Jan Hula,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Patrick Xia,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Raghavendra Pappagari,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  R Thomas McCoy,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Roma Patel,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Najoung Kim,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Yinghui Huang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Katherin Yu,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and  others
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 57th Conference of the Association for Computational Linguistics, </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1812.10860" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/P19-1439/" class="btn btn-sm z-depth-0" role="button" target="_blank">ACL 2019</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant#papers" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Natural language understanding has recently seen a surge of progress with the use of sentence encoders like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) which are pretrained on variants of language modeling. We conduct the first large-scale systematic study of candidate pretraining tasks, comparing 19 different tasks both as alternatives and complements to language modeling. Our primary results support the use language modeling, especially when combined with pretraining on additional labeled-data tasks. However, our results are mixed across pretraining tasks and show some concerning trends: In ELMo’s pretrain-then-freeze paradigm, random baselines are worryingly strong and results vary strikingly across target tasks. In addition, fine-tuning BERT on an intermediate task often negatively impacts downstream transfer. In a more positive trend, we see modest gains from multitask training, suggesting the development of more sophisticated multitask and transfer learning techniques as an avenue for further research.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/S19-1026/" target="_blank">*SEM</a></abbr>
    
  
  </div>

  <div id="kim2019probing" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1904.11544.pdf" target="_blank"><div class="title">Probing What Different NLP Tasks Teach Machines about Function Word Comprehension</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Najoung Kim,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Roma Patel,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Adam Poliak,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Patrick Xia,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alex Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tom McCoy,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alexis Ross,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tal Linzen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Benjamin Van Durme,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and  others
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM), </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1904.11544" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/S19-1026/" class="btn btn-sm z-depth-0" role="button" target="_blank">*SEM 2019</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant#papers" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We introduce a set of nine challenge tasks that test for the understanding of function words. These tasks are created by structurally mutating sentences from existing datasets to target the comprehension of specific types of function words (e.g., prepositions, wh-words). Using these probing tasks, we explore the effects of various pretraining objectives for sentence encoders (e.g., language modeling, CCG supertagging and natural language inference (NLI)) on the learned representations. Our results show that pretraining on CCG—our most syntactic objective—performs the best on average across our probing tasks, suggesting that syntactic knowledge helps function word comprehension. Language modeling also shows strong performance, supporting its widespread use for pretraining state-of-the-art NLP models. Overall, no pretraining objective dominates across the board, and our function word probing tasks highlight several intuitive differences between pretraining objectives, e.g., that NLI helps the comprehension of negation.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://openreview.net/forum?id=SJzSgnRcKX" target="_blank">ICLR</a></abbr>
    
  
  </div>

  <div id="tenney2019what" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1905.06316.pdf" target="_blank"><div class="title">What do you learn from context? Probing for sentence structure in contextualized word representations</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Patrick Xia,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Berlin Chen,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Alex Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Adam Poliak,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  R Thomas McCoy,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Najoung Kim,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Benjamin Van Durme,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Sam Bowman,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Dipanjan Das,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Ellie Pavlick
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Learning Representations, </em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1905.06316" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://openreview.net/forum?id=SJzSgnRcKX" class="btn btn-sm z-depth-0" role="button" target="_blank">ICLR 2019</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/nyu-mll/jiant-v1-legacy/tree/master/probing" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
      
      <a href="/assets/pdf/edgeprobe-poster-iclr-2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.aclweb.org/anthology/D18-1028/" target="_blank">EMNLP</a></abbr>
    
  
  </div>

  <div id="faruqui2018wikiatomicedits" class="col-sm-8">
    
      
        <a href="https://arxiv.org/pdf/1808.09422.pdf" target="_blank"><div class="title">WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling Language and Discourse</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Manaal Faruqui,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Ellie Pavlick,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Dipanjan Das
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, </em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://arxiv.org/abs/1808.09422" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      
      <a href="https://www.aclweb.org/anthology/D18-1028/" class="btn btn-sm z-depth-0" role="button" target="_blank">EMNLP 2018</a>
      
    
    
    
    
    
    
    
      <a href="https://github.com/google-research-datasets/wiki-atomic-edits" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i>Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We release a corpus of 43 million atomic edits across 8 languages. These edits are mined from Wikipedia edit history and consist of instances in which a human editor has inserted a single contiguous phrase into, or deleted a single contiguous phrase from, an existing sentence. We use the collected data to show that the language generated during editing differs from the language that we observe in standard corpora, and that models trained on edits encode different aspects of semantics and discourse than models trained on raw text. We release the full corpus as a resource to aid ongoing research in semantics, discourse, and representation learning.</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

<div class="publications">

<h2 class="year">Older</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="tenney2016collisional" class="col-sm-8">
    
      
        <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.93.013421" target="_blank"><div class="title">Collisional decoherence and rotational quasirevivals in asymmetric-top molecules</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian F Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Maxim Artamonov,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Tamar Seideman,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Philip H Bucksbaum
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Physical Review A, </em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="liekhus2015ultrafast" class="col-sm-8">
    
      
        <a href="https://www.nature.com/articles/ncomms9199" target="_blank"><div class="title">Ultrafast isomerization initiated by X-ray core ionization</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  CE Liekhus-Schmaltz,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>I Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  T Osipov,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  A Sanchez-Gonzalez,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  N Berrah,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  R Boll,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  C Bomme,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  C Bostedt,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JD Bozek,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  S Carron,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  R Coffee,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  J Devin,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  B Erk,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  KR Ferguson,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  RW Field,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  L Foucar,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  LJ Frasinski,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JM Glownia,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  M Gühr,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  A Kamalov,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  J Krzywinski,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  H Li,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JP Marangos,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  TJ Martinez,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  BK McFarland,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  S Miyabe,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  B Murphy,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  A Natan,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  D Rolles,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  A Rudenko,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  M Siano,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  ER Simpson,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  L Spector,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  M Swiggers,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  D Walke,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  S Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  T Weber,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  PH Bucksbaum,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and VSS Petrovic
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Nature communications, </em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="mcfarland2014ultrafast" class="col-sm-8">
    
      
        <a href="https://www.nature.com/articles/ncomms5235" target="_blank"><div class="title">Ultrafast X-ray Auger probing of photoexcited molecular dynamics</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  BK McFarland,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JP Farrell,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  S Miyabe,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  F Tarantelli,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  A Aguilar,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  N Berrah,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  C Bostedt,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JD Bozek,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  PH Bucksbaum,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JC Castagna,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  RN Coffee,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JP Cryan,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  L Fang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  R Feifel,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  KJ Gaffney,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JM Glownia,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  TJ Martinez,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  M Mucke,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  B Murphy,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  A Natan,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  T Osipov,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  VS Petrovic,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  S Schorb,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Th Schultz,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  LS Spector,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  M Swiggers,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>I Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  S Wang,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  JL White,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  W White,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and M Gühr
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Nature communications, </em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="simon2012semicrystalline" class="col-sm-8">
    
      
        <a href="https://pubs.acs.org/doi/abs/10.1021/ma302311h" target="_blank"><div class="title">Semicrystalline dihydroxyacetone copolymers derived from glycerol</div></a>
      
      <div class="author">
        
          <!--  -->
          
          
          
          
            
              
                
                  Jeff Simon,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Johan V Olsson,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  Hyunuk Kim,
                
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                <em>Ian F Tenney</em>,
              
            
          
        
          <!--  -->
          
          
          
          
            
              
                
                  and Robert M Waymouth
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Macromolecules, </em>
      
      
        2012
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2024 Ian  Tenney.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: February 21, 2024.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  

  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
